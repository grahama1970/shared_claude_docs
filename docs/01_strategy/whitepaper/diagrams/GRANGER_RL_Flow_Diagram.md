# GRANGER Reinforcement Learning Flow Diagram

## Dynamic Module Orchestration with RL

```mermaid
%%{init: {
  'theme': 'base',
  'themeVariables': {
    'primaryColor': '#1e293b',
    'primaryTextColor': '#f8fafc',
    'primaryBorderColor': '#64748b',
    'lineColor': '#64748b',
    'secondaryColor': '#334155',
    'tertiaryColor': '#475569',
    'background': '#0f172a',
    'mainBkg': '#1e293b',
    'secondBkg': '#334155',
    'tertiaryBkg': '#475569',
    'primaryBorderColor': '#64748b',
    'secondaryBorderColor': '#64748b',
    'tertiaryBorderColor': '#64748b',
    'primaryTextColor': '#f8fafc',
    'secondaryTextColor': '#e2e8f0',
    'tertiaryTextColor': '#cbd5e1',
    'textColor': '#f8fafc',
    'lineColor': '#64748b',
    'fontFamily': 'ui-monospace, SFMono-Regular, SF Mono, Consolas, Liberation Mono, Menlo, monospace'
  }
}}%%

graph TD
    %% Entry Point
    USER[ğŸ§‘â€ğŸ’¼ User Request<br/>Any Complexity Level 0-3] -->|Task Analysis| BRAIN

    %% Central RL Brain
    BRAIN[ğŸ§  RL Orchestrator<br/>Claude Module Communicator<br/>+ RL Commons]
    
    %% RL Decision Components
    BRAIN -->|Feature Extraction| ANALYZE[ğŸ“Š Task Analyzer<br/>â€¢ Complexity Detection<br/>â€¢ Requirement Parsing<br/>â€¢ Constraint Identification]
    
    ANALYZE -->|State Creation| STATE[ğŸ¯ System State<br/>â€¢ Module Availability<br/>â€¢ Current Load<br/>â€¢ Historical Performance]
    
    STATE -->|Optimization| OLLAMA[ğŸ¤– Ollama LLM<br/>Route Optimization<br/>Real-time Decisions]
    
    OLLAMA -->|Route Selection| ROUTER[ğŸ”€ Dynamic Router<br/>â€¢ Baseline vs Optimized<br/>â€¢ Multi-objective Balance<br/>â€¢ Parallel/Sequential]

    %% Module Pool - All Interchangeable
    ROUTER -.->|Fluid Selection| MODULES{ğŸ² Module Pool<br/>Task-Driven Selection}
    
    %% Individual Modules with Capabilities
    MODULES --> MARKER[ğŸ“„ Marker<br/>PDF/PPT/HTML<br/>Table Extraction]
    MODULES --> SPARTA[ğŸ›¡ï¸ SPARTA<br/>Security Analysis<br/>Vulnerability Detection]
    MODULES --> ARANGODB[ğŸ•¸ï¸ ArangoDB<br/>Graph Storage<br/>Relationship Mapping]
    MODULES --> ARXIV[ğŸ“š ArXiv MCP<br/>Research Papers<br/>Latest Techniques]
    MODULES --> YOUTUBE[ğŸ“º YouTube<br/>Video Transcripts<br/>Technical Content]
    MODULES --> CHAT[ğŸ’¬ Chat<br/>Natural Language<br/>User Interface]
    MODULES --> CLAUDE_MAX[ğŸ”® Claude Max<br/>Multi-LLM Access<br/>GPT/Gemini/Claude]
    MODULES --> TEST_REPORTER[âœ… Test Reporter<br/>Quality Validation<br/>AI Analysis]
    MODULES --> UNSLOTH[ğŸ¦¥ Unsloth<br/>Fine-tuning<br/>Domain Adaptation]
    MODULES --> SCREENSHOT[ğŸ“¸ MCP Screenshot<br/>Visual Analysis<br/>UI Verification]

    %% Dynamic Interconnections (any module can connect to any other)
    MARKER -.->|Discovered Need| ARXIV
    ARXIV -.->|Related Security| SPARTA
    SPARTA -.->|Store Findings| ARANGODB
    ARANGODB -.->|Query Results| CHAT
    YOUTUBE -.->|Training Data| UNSLOTH
    SCREENSHOT -.->|Visual Test| TEST_REPORTER
    CLAUDE_MAX -.->|Multi-Model| TEST_REPORTER

    %% Learning Feedback Loop
    MARKER -->|Episode Data| FEEDBACK[ğŸ“ˆ Learning System<br/>â€¢ Episode Collection<br/>â€¢ Reward Calculation<br/>â€¢ Pattern Discovery]
    SPARTA -->|Performance| FEEDBACK
    ARANGODB -->|Metrics| FEEDBACK
    ARXIV -->|Success Rate| FEEDBACK
    
    FEEDBACK -->|Continuous Improvement| BRAIN
    
    %% Self-Improvement Engine
    FEEDBACK -->|Patterns| IMPROVE[ğŸ”¬ Self-Improvement<br/>â€¢ Bottleneck Detection<br/>â€¢ New Route Discovery<br/>â€¢ Module Optimization]
    
    IMPROVE -->|Updates| BRAIN

    %% Output
    MODULES -->|Task Completion| RESULT[âœ¨ Optimized Result<br/>â€¢ 80% Faster<br/>â€¢ 95% Accuracy<br/>â€¢ Self-Improving]
    
    RESULT -->|Deliver| USER

    %% Styling for visibility in both modes
    classDef brainNode fill:#3b82f6,stroke:#1e40af,color:#ffffff,stroke-width:3px
    classDef moduleNode fill:#10b981,stroke:#047857,color:#ffffff,stroke-width:2px
    classDef analysisNode fill:#f59e0b,stroke:#d97706,color:#ffffff,stroke-width:2px
    classDef feedbackNode fill:#8b5cf6,stroke:#6d28d9,color:#ffffff,stroke-width:2px
    classDef userNode fill:#ef4444,stroke:#b91c1c,color:#ffffff,stroke-width:3px
    
    class BRAIN brainNode
    class MARKER,SPARTA,ARANGODB,ARXIV,YOUTUBE,CHAT,CLAUDE_MAX,TEST_REPORTER,UNSLOTH,SCREENSHOT moduleNode
    class ANALYZE,STATE,OLLAMA,ROUTER,MODULES analysisNode
    class FEEDBACK,IMPROVE feedbackNode
    class USER,RESULT userNode
```

## Key Insights Visualized

1. **ğŸ§  Central RL Brain**: The Claude Module Communicator with RL Commons acts as the intelligent orchestrator, not a fixed pipeline

2. **ğŸ² Fluid Module Selection**: The dotted lines show that ANY module can connect to ANY other module based on task needs

3. **ğŸ“Š Complexity Handling**: The system analyzes each task and adapts its approach from Level 0 (simple) to Level 3 (expert)

4. **ğŸ”€ Dynamic Routing**: Real-time decisions between baseline and optimized routes, with parallel/sequential execution

5. **ğŸ“ˆ Continuous Learning**: Every interaction feeds back into the system, making it smarter for future tasks

6. **ğŸ”¬ Self-Improvement**: The system discovers new patterns and optimizations autonomously

## Example Task Flows

### Level 0: Simple PDF Extraction
USER â†’ BRAIN â†’ MARKER â†’ RESULT

### Level 1: PDF with Security Check  
USER â†’ BRAIN â†’ MARKER â†’ SPARTA â†’ RESULT

### Level 2: Multi-Source Verification
USER â†’ BRAIN â†’ (MARKER + YOUTUBE) â†’ ARANGODB â†’ CHAT â†’ RESULT

### Level 3: Complex Hardware Verification
USER â†’ BRAIN â†’ MARKER â†’ (SPARTA || ARXIV || ARANGODB) â†’ CLAUDE_MAX â†’ TEST_REPORTER â†’ RESULT

The beauty is that these flows are NOT pre-programmed - they emerge from RL optimization based on what works best for each unique task.
